{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f1436a0-3357-4850-b507-a12c76e60c22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Chapter 2: Advanced Operations in Spark Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c029f8c-dfbc-4e10-b09d-ccbea7b62eec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Salary dataframe"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Employee: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Salary: long (nullable = true)\n\n+--------+----------+------+\n|Employee|Department|Salary|\n+--------+----------+------+\n|    John| Field-eng|  3500|\n| Michael| Field-eng|  4500|\n|  Robert|      NULL|  4000|\n|   Maria|   Finance|  3500|\n|    John|     Sales|  3000|\n|   Kelly|   Finance|  3500|\n|    Kate|   Finance|  3000|\n|  Martin|      NULL|  3500|\n|   Kiran|     Sales|  2200|\n| Michael| Field-eng|  4500|\n+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data = [(\"John\", \"Field-eng\", 3500), \n",
    "    (\"Michael\", \"Field-eng\", 4500), \n",
    "    (\"Robert\", None, 4000), \n",
    "    (\"Maria\", \"Finance\", 3500), \n",
    "    (\"John\", \"Sales\", 3000), \n",
    "    (\"Kelly\", \"Finance\", 3500), \n",
    "    (\"Kate\", \"Finance\", 3000), \n",
    "    (\"Martin\", None, 3500), \n",
    "    (\"Kiran\", \"Sales\", 2200), \n",
    "    (\"Michael\", \"Field-eng\", 4500) \n",
    "  ]\n",
    "columns= [\"Employee\", \"Department\", \"Salary\"]\n",
    "salary_data = spark.createDataFrame(data = salary_data, schema = columns)\n",
    "salary_data.printSchema()\n",
    "salary_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c64523b-97f8-4cdf-8c73-13723a7f7453",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using Groupby in a Dataframe"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|Department|count|\n+----------+-----+\n| Field-eng|    3|\n|      NULL|    2|\n|   Finance|    3|\n|     Sales|    2|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data.groupby('Department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e2c600-8160-4138-968f-835e6757f06c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n|Department|       avg(Salary)|\n+----------+------------------+\n| Field-eng| 4166.666666666667|\n|      NULL|            3750.0|\n|   Finance|3333.3333333333335|\n|     Sales|            2600.0|\n+----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data.groupby('Department').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d437c9f0-2336-4687-83b4-7c8142b4085f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Complex Groupby Statement"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n|Department|Salary|\n+----------+------+\n|      NULL|  7500|\n| Field-eng| 12500|\n|   Finance| 10000|\n|     Sales|  5200|\n+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "salary_data.groupBy('Department')\\\n",
    "  .sum('Salary')\\\n",
    "  .withColumn('sum(Salary)',round(col('sum(Salary)'), 2))\\\n",
    "  .withColumnRenamed('sum(Salary)', 'Salary')\\\n",
    "  .orderBy('Department')\\\n",
    "  .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfc73dea-aa0c-4a54-aded-a4c3814f01a9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Joining Dataframes in Spark"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+\n| ID|Employee|Department|Salary|\n+---+--------+----------+------+\n|  1|    John| Field-eng|  3500|\n|  2|  Robert|     Sales|  4000|\n|  3|   Maria|   Finance|  3500|\n|  4| Michael|     Sales|  3000|\n|  5|   Kelly|   Finance|  3500|\n|  6|    Kate|   Finance|  3000|\n|  7|  Martin|   Finance|  3500|\n|  8|   Kiran|     Sales|  2200|\n+---+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id = [(1, \"John\", \"Field-eng\", 3500), \\\n",
    "    (2, \"Robert\", \"Sales\", 4000), \\\n",
    "    (3, \"Maria\", \"Finance\", 3500), \\\n",
    "    (4, \"Michael\", \"Sales\", 3000), \\\n",
    "    (5, \"Kelly\", \"Finance\", 3500), \\\n",
    "    (6, \"Kate\", \"Finance\", 3000), \\\n",
    "    (7, \"Martin\", \"Finance\", 3500), \\\n",
    "    (8, \"Kiran\", \"Sales\", 2200), \\\n",
    "  ]\n",
    "columns= [\"ID\", \"Employee\", \"Department\", \"Salary\"]\n",
    "salary_data_with_id = spark.createDataFrame(data = salary_data_with_id, schema = columns)\n",
    "salary_data_with_id.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "125e73d8-c716-4e1c-8900-859c1ec666e9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Employee data"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n| ID|State|Gender|\n+---+-----+------+\n|  1|   NY|     M|\n|  2|   NC|     M|\n|  3|   NY|     F|\n|  4|   TX|     M|\n|  5|   NY|     F|\n|  6|   AZ|     F|\n+---+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data = [(1, \"NY\", \"M\"), \\\n",
    "    (2, \"NC\", \"M\"), \\\n",
    "    (3, \"NY\", \"F\"), \\\n",
    "    (4, \"TX\", \"M\"), \\\n",
    "    (5, \"NY\", \"F\"), \\\n",
    "    (6, \"AZ\", \"F\") \\\n",
    "  ]\n",
    "columns= [\"ID\", \"State\", \"Gender\"]\n",
    "employee_data = spark.createDataFrame(data = employee_data, schema = columns)\n",
    "employee_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0137bf4-d318-4417-86ca-df79f2fb80be",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inner join"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+---+-----+------+\n| ID|Employee|Department|Salary| ID|State|Gender|\n+---+--------+----------+------+---+-----+------+\n|  1|    John| Field-eng|  3500|  1|   NY|     M|\n|  2|  Robert|     Sales|  4000|  2|   NC|     M|\n|  3|   Maria|   Finance|  3500|  3|   NY|     F|\n|  4| Michael|     Sales|  3000|  4|   TX|     M|\n|  5|   Kelly|   Finance|  3500|  5|   NY|     F|\n|  6|    Kate|   Finance|  3000|  6|   AZ|     F|\n+---+--------+----------+------+---+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id.join(employee_data,salary_data_with_id.ID ==  employee_data.ID,\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f34ff657-b0dd-4485-96f0-6d7c6126a1bd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Outer join"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+----+-----+------+\n| ID|Employee|Department|Salary|  ID|State|Gender|\n+---+--------+----------+------+----+-----+------+\n|  1|    John| Field-eng|  3500|   1|   NY|     M|\n|  2|  Robert|     Sales|  4000|   2|   NC|     M|\n|  3|   Maria|   Finance|  3500|   3|   NY|     F|\n|  4| Michael|     Sales|  3000|   4|   TX|     M|\n|  5|   Kelly|   Finance|  3500|   5|   NY|     F|\n|  6|    Kate|   Finance|  3000|   6|   AZ|     F|\n|  7|  Martin|   Finance|  3500|NULL| NULL|  NULL|\n|  8|   Kiran|     Sales|  2200|NULL| NULL|  NULL|\n+---+--------+----------+------+----+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id.join(employee_data,salary_data_with_id.ID ==  employee_data.ID,\"outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "868ca315-ab44-4eb6-b8f1-92481d770911",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Left join"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+----+-----+------+\n| ID|Employee|Department|Salary|  ID|State|Gender|\n+---+--------+----------+------+----+-----+------+\n|  1|    John| Field-eng|  3500|   1|   NY|     M|\n|  2|  Robert|     Sales|  4000|   2|   NC|     M|\n|  3|   Maria|   Finance|  3500|   3|   NY|     F|\n|  4| Michael|     Sales|  3000|   4|   TX|     M|\n|  6|    Kate|   Finance|  3000|   6|   AZ|     F|\n|  5|   Kelly|   Finance|  3500|   5|   NY|     F|\n|  7|  Martin|   Finance|  3500|NULL| NULL|  NULL|\n|  8|   Kiran|     Sales|  2200|NULL| NULL|  NULL|\n+---+--------+----------+------+----+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id.join(employee_data,salary_data_with_id.ID ==  employee_data.ID,\"left\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cba2965-54b3-4d04-a456-77e9d9af6e1f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Right join"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+---+-----+------+\n| ID|Employee|Department|Salary| ID|State|Gender|\n+---+--------+----------+------+---+-----+------+\n|  1|    John| Field-eng|  3500|  1|   NY|     M|\n|  2|  Robert|     Sales|  4000|  2|   NC|     M|\n|  3|   Maria|   Finance|  3500|  3|   NY|     F|\n|  4| Michael|     Sales|  3000|  4|   TX|     M|\n|  5|   Kelly|   Finance|  3500|  5|   NY|     F|\n|  6|    Kate|   Finance|  3000|  6|   AZ|     F|\n+---+--------+----------+------+---+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id.join(employee_data,salary_data_with_id.ID ==  employee_data.ID,\"right\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd9f95c1-4109-4ceb-925d-7b10cf838fdd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Union"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- ID: long (nullable = true)\n |-- Employee: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Salary: long (nullable = true)\n\n+---+--------+----------+------+\n|ID |Employee|Department|Salary|\n+---+--------+----------+------+\n|1  |John    |Field-eng |3500  |\n|2  |Robert  |Sales     |4000  |\n|3  |Aliya   |Finance   |3500  |\n|4  |Nate    |Sales     |3000  |\n+---+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id_2 = [(1, \"John\", \"Field-eng\", 3500), \\\n",
    "    (2, \"Robert\", \"Sales\", 4000), \\\n",
    "    (3, \"Aliya\", \"Finance\", 3500), \\\n",
    "    (4, \"Nate\", \"Sales\", 3000), \\\n",
    "  ]\n",
    "columns2= [\"ID\", \"Employee\", \"Department\", \"Salary\"]\n",
    "\n",
    "salary_data_with_id_2 = spark.createDataFrame(data = salary_data_with_id_2, schema = columns2)\n",
    "\n",
    "salary_data_with_id_2.printSchema()\n",
    "salary_data_with_id_2.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb3d433-2a89-47b4-9d21-2d79194809c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+\n|ID |Employee|Department|Salary|\n+---+--------+----------+------+\n|1  |John    |Field-eng |3500  |\n|2  |Robert  |Sales     |4000  |\n|3  |Maria   |Finance   |3500  |\n|4  |Michael |Sales     |3000  |\n|5  |Kelly   |Finance   |3500  |\n|6  |Kate    |Finance   |3000  |\n|7  |Martin  |Finance   |3500  |\n|8  |Kiran   |Sales     |2200  |\n|1  |John    |Field-eng |3500  |\n|2  |Robert  |Sales     |4000  |\n|3  |Aliya   |Finance   |3500  |\n|4  |Nate    |Sales     |3000  |\n+---+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "unionDF = salary_data_with_id.union(salary_data_with_id_2)\n",
    "unionDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d84b0031-6f62-41a8-9533-b510a487ab0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Reading and Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd687938-3137-4fa0-bbdf-d20c17d14265",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>Employee</th><th>Department</th><th>Salary</th></tr></thead><tbody><tr><td>1</td><td>John</td><td>Field-eng</td><td>3500</td></tr><tr><td>2</td><td>Robert</td><td>Sales</td><td>4000</td></tr><tr><td>3</td><td>Maria</td><td>Finance</td><td>3500</td></tr><tr><td>4</td><td>Michael</td><td>Sales</td><td>3000</td></tr><tr><td>5</td><td>Kelly</td><td>Finance</td><td>3500</td></tr><tr><td>6</td><td>Kate</td><td>Finance</td><td>3000</td></tr><tr><td>7</td><td>Martin</td><td>Finance</td><td>3500</td></tr><tr><td>8</td><td>Kiran</td><td>Sales</td><td>2200</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "John",
         "Field-eng",
         3500
        ],
        [
         2,
         "Robert",
         "Sales",
         4000
        ],
        [
         3,
         "Maria",
         "Finance",
         3500
        ],
        [
         4,
         "Michael",
         "Sales",
         3000
        ],
        [
         5,
         "Kelly",
         "Finance",
         3500
        ],
        [
         6,
         "Kate",
         "Finance",
         3000
        ],
        [
         7,
         "Martin",
         "Finance",
         3500
        ],
        [
         8,
         "Kiran",
         "Sales",
         2200
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "ID",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(salary_data_with_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "961c873c-41d9-4f19-989e-c1c45a3a1c2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "salary_data_with_id.write.csv('salary_data.csv', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c8eb85-7d75-4010-977d-370b7940b57e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading and writing CSV files"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+\n| ID|Employee|Department|Salary|\n+---+--------+----------+------+\n|  1|    John| Field-eng|  3500|\n|  2|  Robert|     Sales|  4000|\n|  3|   Maria|   Finance|  3500|\n|  4| Michael|     Sales|  3000|\n|  5|   Kelly|   Finance|  3500|\n|  6|    Kate|   Finance|  3000|\n|  7|  Martin|   Finance|  3500|\n|  8|   Kiran|     Sales|  2200|\n+---+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_coming_from_csv=spark.read.csv('/salary_data.csv', header=True)\n",
    "\n",
    "df_coming_from_csv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "982c8739-fbf9-437f-93a8-1659ecbe071b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Schema on read**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b033bc47-7a90-4ae1-b37b-692860e06482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+\n| ID|  State|   Gender|\n+---+-------+---------+\n|  1|   John|Field-eng|\n|  2| Robert|    Sales|\n|  3|  Maria|  Finance|\n|  4|Michael|    Sales|\n|  5|  Kelly|  Finance|\n|  6|   Kate|  Finance|\n|  7| Martin|  Finance|\n|  8|  Kiran|    Sales|\n+---+-------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "filePath = '/salary_data.csv'\n",
    "columns= [\"ID\", \"State\", \"Gender\"] \n",
    "schema = StructType([\n",
    "      StructField(\"ID\", IntegerType(),True),\n",
    "  StructField(\"State\",  StringType(),True),\n",
    "  StructField(\"Gender\",  StringType(),True)\n",
    "])\n",
    " \n",
    "read_data = spark.read.format(\"csv\").option(\"header\",\"true\").schema(schema).load(filePath)\n",
    "read_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54cb15f4-3c92-4ea4-ab83-357413caf354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "salary_data_with_id.write.parquet('salary_data.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfd8f639-d141-48c9-be8e-dffd764aa0ee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading and writing Parquet files"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+\n| ID|Employee|Department|Salary|\n+---+--------+----------+------+\n|  5|   Kelly|   Finance|  3500|\n|  6|    Kate|   Finance|  3000|\n|  1|    John| Field-eng|  3500|\n|  2|  Robert|     Sales|  4000|\n|  3|   Maria|   Finance|  3500|\n|  4| Michael|     Sales|  3000|\n|  7|  Martin|   Finance|  3500|\n|  8|   Kiran|     Sales|  2200|\n+---+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.read.parquet('/salary_data.parquet').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "492b344b-3719-44cd-a8dc-034d20f3a409",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading and writing ORC files"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+\n| ID|Employee|Department|Salary|\n+---+--------+----------+------+\n|  5|   Kelly|   Finance|  3500|\n|  6|    Kate|   Finance|  3000|\n|  1|    John| Field-eng|  3500|\n|  2|  Robert|     Sales|  4000|\n|  7|  Martin|   Finance|  3500|\n|  8|   Kiran|     Sales|  2200|\n|  3|   Maria|   Finance|  3500|\n|  4| Michael|     Sales|  3000|\n+---+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id.write.orc('salary_data.orc', mode='overwrite')\n",
    "spark.read.orc('/salary_data.orc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b3c1309-4a00-4a92-ac3e-7f2a9d491445",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading and writing Delta files"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------+------+\n| ID|Employee|Department|Salary|\n+---+--------+----------+------+\n|  5|   Kelly|   Finance|  3500|\n|  6|    Kate|   Finance|  3000|\n|  1|    John| Field-eng|  3500|\n|  2|  Robert|     Sales|  4000|\n|  3|   Maria|   Finance|  3500|\n|  4| Michael|     Sales|  3000|\n|  7|  Martin|   Finance|  3500|\n|  8|   Kiran|     Sales|  2200|\n+---+--------+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "salary_data_with_id.write.format(\"delta\").save(\"/FileStore/tables/salary_data_with_id\", mode='overwrite')\n",
    "df = spark.read.load(\"/FileStore/tables/salary_data_with_id\")\n",
    "df.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 969987236417588,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Chapter 2_ Advanced Operations in Spark Code",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}